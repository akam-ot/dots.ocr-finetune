{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tune dots.ocr for Custom OCR Tasks\n",
        "\n",
        "This notebook shows how to fine-tune the dots.ocr model for custom OCR tasks on Google Colab.\n",
        "\n",
        "> **Note:** This notebook makes use of wjbmattingly's [dots.ocr training repo](https://github.com/wjbmattingly/dots.ocr).  \n",
        "\n",
        "## What is in this notebook:\n",
        "- Autolabel images using the base dots.ocr model\n",
        "- Prepare training data from your custom images\n",
        "- Finetune the model for better OCR on your specific content\n",
        "- Test and evaluate your finetuned model\n",
        "\n",
        "## Requirements:\n",
        "- A100/L4 GPU recommended\n",
        "- Images you want to train on (upload to Google Drive)\n",
        "\n",
        "## Workflow:\n",
        "1. Setup - Install dependencies and download base model\n",
        "2. Auto-label - Generate initial OCR predictions (skip if you have prepared data)\n",
        "3. Correct - Manually fix the generated labels (skip if you have prepared data)\n",
        "4. Train- Finetune the model on your corrected data\n",
        "5. Test - Evaluate the model"
      ],
      "metadata": {
        "id": "MGAN1mYy9Xzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Environment Setup\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Set memory allocation for better GPU usage\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "# Check GPU availability\n",
        "print(\"Checking GPU...\")\n",
        "!nvidia-smi\n",
        "\n",
        "# Clone repository\n",
        "if not os.path.exists(\"dots.ocr\"):\n",
        "    !git clone https://github.com/wjbmattingly/dots.ocr.git\n",
        "\n",
        "%cd dots.ocr\n",
        "\n",
        "# Install dependencies\n",
        "!pip install -q -r requirements.txt -r training_requirements.txt\n",
        "!pip install -e .\n",
        "\n",
        "# Download base model weights (~6GB)\n",
        "!python tools/download_model.py\n",
        "\n",
        "print(\"Setup complete\")\n"
      ],
      "metadata": {
        "id": "1TgYIuAfdzhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Mount Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# Set up paths\n",
        "IMAGES_DIR = \"/content/drive/MyDrive/images\"  # Upload your images here\n",
        "AUTOLABEL_DIR = \"/content/autolabel\"  # Autolabeled results\n",
        "\n",
        "print(f\"Images directory: {IMAGES_DIR}\")\n",
        "print(f\"Autolabel directory: {AUTOLABEL_DIR}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjFRcRx5d7Gg",
        "outputId": "6c993239-f86b-445e-92f2-d70fce65ee7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Images directory: /content/drive/MyDrive/images\n",
            "Autolabel directory: /content/autolabel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Upload Your Images\n",
        "\n",
        "**Before proceeding:**\n",
        "1. Go to Google Drive and create a folder called 'images' in your My Drive\n",
        "2. Upload the images you want to train on\n",
        "3. Supported formats: .jpg, .jpeg, .png, .pdf\n",
        "\n",
        "\n",
        "\n",
        "Note: If you already have prepared training data, skip to the training section.\n"
      ],
      "metadata": {
        "id": "EHMwNlUBeIGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Autolabel Your Images\n",
        "\n",
        "import os\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(AUTOLABEL_DIR, exist_ok=True)\n",
        "\n",
        "# Find all image files\n",
        "image_files = []\n",
        "for ext in [\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.pdf\"]:\n",
        "    image_files.extend(glob.glob(os.path.join(IMAGES_DIR, ext)))\n",
        "\n",
        "print(f\"Found {len(image_files)} images to process\")\n",
        "\n",
        "if len(image_files) == 0:\n",
        "    print(\"No images found! Please upload images to Google Drive first.\")\n",
        "    print(f\"Expected location: {IMAGES_DIR}\")\n",
        "else:\n",
        "    # Process each image\n",
        "    successful = 0\n",
        "    failed = 0\n",
        "\n",
        "    for img_path in tqdm(image_files, desc=\"Autolabeling\"):\n",
        "        try:\n",
        "            !python -m dots_ocr.parser \"{img_path}\" --output \"{AUTOLABEL_DIR}\" --prompt \"prompt_ocr\" --use_hf true\n",
        "            successful += 1\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to process {os.path.basename(img_path)}: {e}\")\n",
        "            failed += 1\n",
        "\n",
        "    print(f\"\\nAuto-labeling completed!\")\n",
        "    print(f\"Successful: {successful}\")\n",
        "    print(f\"Failed: {failed}\")\n",
        "    print(f\"Results saved to: {AUTOLABEL_DIR}\")\n"
      ],
      "metadata": {
        "id": "YocksYx5ePvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manual Correction\n",
        "\n",
        "\n",
        "### How to correct your labels:\n",
        "\n",
        "1. Download the '/content/autolabel' folder from Colab\n",
        "\n",
        "2. Edit the '.md' files in each subfolder to correct OCR errors\n",
        "\n",
        "3. Upload the corrected folder back to Google Drive:\n",
        "   - Upload the entire corrected 'autolabel' folder to '/content/drive/MyDrive/autolabel'\n",
        "\n",
        "\n",
        "\n",
        "Skip this section if you already have prepared training data."
      ],
      "metadata": {
        "id": "lB7o4kxt-dbN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Training Data\n",
        "\n",
        "Expected data format: Your data should be in '/content/drive/MyDrive/autolabel/' with this structure:\n",
        "\n",
        "    autolabel/\n",
        "    ├── sample1/\n",
        "    │   ├── sample1.jpg\n",
        "    │   ├── sample1.md\n",
        "    │   └── sample1.json\n",
        "    ├── sample2/\n",
        "    │   ├── sample2.jpg\n",
        "    │   ├── sample2.md\n",
        "    │   └── sample2.json\n",
        "    └── ...\n"
      ],
      "metadata": {
        "id": "9L8c-O33-g4Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training JSONL Format**\n",
        "\n",
        "Your corrected data will be converted into a `.jsonl` file for training (`train_ocr_resized.jsonl`).  \n",
        "Each line in this file is one training sample in JSON format.\n",
        "\n",
        "**Expected JSONL structure:**\n",
        "\n",
        "```json\n",
        "{\"messages\":[\n",
        "  {\"role\":\"user\",\"content\":[\n",
        "    {\"type\":\"image\",\"image\":\"/content/resized_images/sample1.jpg\"},\n",
        "    {\"type\":\"text\",\"text\":\"prompt_ocr\"}\n",
        "  ]},\n",
        "  {\"role\":\"assistant\",\"content\":\"This is the corrected OCR text for sample 1.\"}\n",
        "]}\n",
        "{\"messages\":[\n",
        "  {\"role\":\"user\",\"content\":[\n",
        "    {\"type\":\"image\",\"image\":\"/content/resized_images/sample2.jpg\"},\n",
        "    {\"type\":\"text\",\"text\":\"prompt_ocr\"}\n",
        "  ]},\n",
        "  {\"role\":\"assistant\",\"content\":\"This is the corrected OCR text for sample 2.\"}\n",
        "]}\n"
      ],
      "metadata": {
        "id": "DEJP7Naz_T-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# resizing images and preparing training data\n",
        "import os\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from dots_ocr.utils.prompts import dict_promptmode_to_prompt\n",
        "\n",
        "# Set up paths\n",
        "CORRECTED_DIR = \"/content/drive/MyDrive/autolabel\"  # Your corrected labels\n",
        "RESIZED_DIR = \"/content/resized_images\"\n",
        "TRAINING_JSONL = \"/content/drive/MyDrive/train_ocr_resized.jsonl\"\n",
        "\n",
        "os.makedirs(RESIZED_DIR, exist_ok=True)\n",
        "prompt = dict_promptmode_to_prompt[\"prompt_ocr\"]\n",
        "\n",
        "def list_samples(base_dir):\n",
        "    \"\"\"List all sample directories\"\"\"\n",
        "    if not os.path.exists(base_dir):\n",
        "        return []\n",
        "    return [d for d in sorted(os.listdir(base_dir)) if os.path.isdir(os.path.join(base_dir, d))]\n",
        "\n",
        "def read_original_image_path(base_dir, name):\n",
        "    \"\"\"Get original image path from metadata\"\"\"\n",
        "    jsonl_path = os.path.join(base_dir, f\"{name}.jsonl\")\n",
        "    if os.path.exists(jsonl_path):\n",
        "        with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            for line in f:\n",
        "                try:\n",
        "                    obj = json.loads(line)\n",
        "                    if \"file_path\" in obj:\n",
        "                        return obj[\"file_path\"]\n",
        "                except:\n",
        "                    pass\n",
        "    # Fallback to sample directory\n",
        "    return os.path.join(base_dir, name, f\"{name}.jpg\")\n",
        "\n",
        "def load_corrected_text(sample_dir, name):\n",
        "    \"\"\"Load corrected text from .md file\"\"\"\n",
        "    md_path = os.path.join(sample_dir, f\"{name}.md\")\n",
        "    if os.path.exists(md_path):\n",
        "        return open(md_path, \"r\", encoding=\"utf-8\").read().strip()\n",
        "    return None\n",
        "\n",
        "def resize_image(src_path, dst_path, max_side=512):\n",
        "    \"\"\"Resize image to reduce memory usage during training\"\"\"\n",
        "    img = Image.open(src_path).convert(\"RGB\")\n",
        "    w, h = img.size\n",
        "    scale = max_side / max(w, h)\n",
        "    if scale < 1.0:\n",
        "        new_w, new_h = int(w * scale), int(h * scale)\n",
        "        img = img.resize((new_w, new_h), Image.Resampling.LANCZOS)\n",
        "    img.save(dst_path)\n",
        "\n",
        "# Check if corrected directory exists\n",
        "if not os.path.exists(CORRECTED_DIR):\n",
        "    print(f\"Corrected directory not found: {CORRECTED_DIR}\")\n",
        "    print(\"Please upload your corrected autolabel folder to Google Drive first.\")\n",
        "else:\n",
        "    # Process samples\n",
        "    samples = list_samples(CORRECTED_DIR)\n",
        "    print(f\"Found {len(samples)} corrected samples\")\n",
        "\n",
        "    if len(samples) == 0:\n",
        "        print(\"No samples found in corrected directory!\")\n",
        "    else:\n",
        "        training_data = []\n",
        "        processed = 0\n",
        "        skipped = 0\n",
        "\n",
        "        for name in tqdm(samples, desc=\"Preparing training data\"):\n",
        "            sample_dir = os.path.join(CORRECTED_DIR, name)\n",
        "\n",
        "            # Get original image and resize it\n",
        "            orig_path = read_original_image_path(CORRECTED_DIR, name)\n",
        "            resized_path = os.path.join(RESIZED_DIR, f\"{name}.jpg\")\n",
        "\n",
        "            try:\n",
        "                resize_image(orig_path, resized_path, max_side=512)\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to resize {name}: {e}\")\n",
        "                skipped += 1\n",
        "                continue\n",
        "\n",
        "            # Load corrected text\n",
        "            text = load_corrected_text(sample_dir, name)\n",
        "            if not text:\n",
        "                print(f\"No corrected text found for {name}\")\n",
        "                skipped += 1\n",
        "                continue\n",
        "\n",
        "            # Create training record\n",
        "            record = {\n",
        "                \"messages\": [\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": [\n",
        "                            {\"type\": \"image\", \"image\": resized_path},\n",
        "                            {\"type\": \"text\", \"text\": prompt}\n",
        "                        ]\n",
        "                    },\n",
        "                    {\"role\": \"assistant\", \"content\": text}\n",
        "                ]\n",
        "            }\n",
        "            training_data.append(record)\n",
        "            processed += 1\n",
        "\n",
        "        # Save training data\n",
        "        with open(TRAINING_JSONL, \"w\", encoding=\"utf-8\") as f:\n",
        "            for record in training_data:\n",
        "                f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "        print(f\"\\nTraining data prepared!\")\n",
        "        print(f\"Processed: {processed} samples\")\n",
        "        print(f\"Skipped: {skipped} samples\")\n",
        "        print(f\"Training file: {TRAINING_JSONL}\")\n",
        "        print(f\"Resized images: {RESIZED_DIR}\")\n"
      ],
      "metadata": {
        "id": "TYuzMOy9eqsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 7. Finetune the Model\n",
        "\n",
        "TRAINING_JSONL = \"/content/drive/MyDrive/train_ocr_resized.jsonl\"\n",
        "\n",
        "# Check if training data exists\n",
        "if not os.path.exists(TRAINING_JSONL):\n",
        "    print(f\"Training data not found: {TRAINING_JSONL}\")\n",
        "    print(\"Please run the previous step to prepare training data first.\")\n",
        "else:\n",
        "    print(\"Starting finetuning...\")\n",
        "\n",
        "    # Train the model\n",
        "    !python train_simple.py \\\n",
        "        --data \"{TRAINING_JSONL}\" \\\n",
        "        --epochs 15 \\\n",
        "        --batch_size 1 \\\n",
        "        --learning_rate 3e-4 \\\n",
        "        --max_length 1024 \\\n",
        "        --gradient_checkpointing \\\n",
        "        --output_dir \"/content/local_checkpoints\"\n",
        "\n",
        "    print(\"Training completed\")\n"
      ],
      "metadata": {
        "id": "czCCIYTgetGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 8. Setup Finetuned Model\n",
        "\n",
        "print(\"Copying configuration files...\")\n",
        "\n",
        "# Ensure we have base model files\n",
        "!python tools/download_model.py\n",
        "\n",
        "# Copy missing configuration files from base model\n",
        "!cp ./weights/DotsOCR/configuration_dots.py /content/local_checkpoints/final_model/\n",
        "!cp ./weights/DotsOCR/modeling_*.py /content/local_checkpoints/final_model/\n",
        "\n",
        "print(\"Replacing base model with finetuned model...\")\n",
        "!rm -rf ./weights/DotsOCR\n",
        "!cp -r /content/local_checkpoints/final_model ./weights/DotsOCR\n",
        "\n",
        "print(\"Verifying model setup...\")\n",
        "!python -c \"import json; json.load(open('./weights/DotsOCR/config.json')); print('Model setup complete')\"\n",
        "\n",
        "print(\"\\nYour finetuned model is ready for inference\")\n",
        "\n"
      ],
      "metadata": {
        "id": "a5uBbGYEe12X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "def sanitize(img_path, dst_dir):\n",
        "    try:\n",
        "        with Image.open(img_path) as im:\n",
        "            im = im.convert(\"RGB\")\n",
        "            w, h = im.size\n",
        "            if max(w, h) > 1024:\n",
        "                s = 1024 / max(w, h)\n",
        "                im = im.resize((int(w*s), int(h*s)), Image.Resampling.LANCZOS)\n",
        "            clean_path = os.path.join(dst_dir, os.path.basename(img_path))\n",
        "            im.save(clean_path, format=\"JPEG\", quality=92, optimize=True)\n",
        "            return clean_path\n",
        "    except Exception as e:\n",
        "        print(f\"[skip bad image] {img_path} -> {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "UUdz9uoImqrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test OCR\n",
        "# Set your file path here:\n",
        "IMAGE_PATH = \"/content/resized_images/SCR-20250715-iho.jpg\"\n",
        "\n",
        "from dots_ocr.parser import DotsOCRParser\n",
        "import os\n",
        "\n",
        "parser = DotsOCRParser(use_hf=True, max_completion_tokens=128)\n",
        "result = parser.parse_file(IMAGE_PATH, prompt_mode=\"prompt_ocr\")\n",
        "\n",
        "if not result:\n",
        "    print(\"[no result]\")\n",
        "else:\n",
        "    info = result[0]\n",
        "    text = None\n",
        "\n",
        "    md_path = info.get(\"md_content_path\")\n",
        "    if md_path and os.path.exists(md_path):\n",
        "        with open(md_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            text = f.read()\n",
        "\n",
        "    if text is None and isinstance(info.get(\"content\"), str):\n",
        "        text = info[\"content\"]\n",
        "\n",
        "    print(text or \"[empty]\")\n"
      ],
      "metadata": {
        "id": "oE8trhvre7Lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 10. Save the Fine-tuned Model\n",
        "print(\"Saving fine-tuned model to Google Drive...\")\n",
        "\n",
        "!cp -r /content/local_checkpoints/final_model /content/drive/MyDrive/dots_ocr_finetuned\n",
        "\n",
        "print(\"\\nFine-tuned model saved to Google Drive\")\n",
        "print(\"Location: /content/drive/MyDrive/dots_ocr_finetuned\")\n"
      ],
      "metadata": {
        "id": "PTpzUStufCYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "### Resources:\n",
        "- [dots.ocr GitHub](https://github.com/rednote-hilab/dots.ocr)\n",
        "- [Training Documentation](https://github.com/wjbmattingly/dots.ocr/blob/main/README_model_training.md)\n",
        "\n",
        "Happy training!"
      ],
      "metadata": {
        "id": "c51dXgzW8bZj"
      }
    }
  ]
}